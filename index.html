<!DOCTYPE html>
<html>
<head>
	<title>Javascript voice recognition</title>
	<meta http-equiv="content-type" content="text/html; charset=UTF-8"/>

	<!-- Bootstrap -->
	<link href="css/bootstrap.min.css" rel="stylesheet" media="screen"/>

	<link href="css/style.css" rel="stylesheet" media="screen"/>
</head>
<body>

<div class="navbar navbar-inverse navbar-static-top">
	<div class="navbar-inner">
		<div class="container">
			<a class="brand" href="index.html">voice-recognition.js</a>
			<div class="nav-collapse collapse">
				<ul class="nav">
					<li class="active">
						<a href="index.html">Home</a>
					</li>
					<li>
						<a href="voice-analysis.html">Voice analysis &amp; comparison</a>
					</li>
					<li>
						<a href="voice-recognition.html">Voice recognition</a>
					</li>
				</ul>
			</div>
		</div>
	</div>
</div>

<div class="container">
	<div class="page-header">
		<h1>Voice recognition <small>powered by Javascript</small></h1>
	</div>
	<div class="hero-unit">
		<img src="img/icon_140.png" alt="Logo" class="pull-right"/>
		<p class="lead">
			<strong>voice-recognition.js</strong> is a Javascript library for low-level voice recognition.
		</p>
		<div class="btn-toolbar">
			<div class="btn-group">
				<a href="voice-recognition.html" class="btn btn-primary btn-large">Voice recognition</a>
				<a href="voice-analysis.html" class="btn btn-large">Voice analysis &amp; comparison</a>
			</div>
			<div class="btn-group">
				<a href="http://github.com/simonser/voice-recognition.js" class="btn btn-large">Github project</a>
			</div>
			<div class="btn-group">
				<a href="doc/js" target="_blank" class="btn btn-large">Javascript reference</a>
			</div>
		</div><!-- /.btn-toolbar -->
	</div>
</div>
<div class="container">
	<div class="row-fluid">
		<div class="span3">
			<div class="well sidebar-nav">
				<ul id="docs-navbar" class="nav nav-list">
					<li class="nav-header">Introduction</li>
						<li><a href="#docs-presentation"><i class="icon-chevron-right"></i> Pr&eacute;sentation</a></li>
						<li><a href="#docs-general-functioning"><i class="icon-chevron-right"></i> Fonctionnement g&eacute;n&eacute;ral</a></li>
					<li class="nav-header">Traitement de la piste audio</li>
						<li><a href="#docs-signal-processing"><i class="icon-chevron-right"></i> Traitement du signal</a></li>
						<li><a href="#docs-fft-processing"><i class="icon-chevron-right"></i> Traitement de la FFT</a></li>
					<li class="nav-header">Comparaison de deux courbes</li>
						<li><a href="#docs-data-preparing"><i class="icon-chevron-right"></i> Pr&eacute;paration des donn&eacute;es</a></li>
						<li><a href="#docs-data-shifting"><i class="icon-chevron-right"></i> D&eacute;calage des courbes</a></li>
						<li><a href="#docs-comparing"><i class="icon-chevron-right"></i> Comparaison des courbes</a></li>
					<li class="nav-header">Traitement final</li>
						<li><a href="#docs-voice-recognition"><i class="icon-chevron-right"></i> Reconnaissance vocale</a></li>
				</ul>
			</div>
		</div>
		<div class="span9 docs">
			<h1>Docs <small>(in French)</small></h1>

			<h2 id="docs-presentation">1. Pr&eacute;sentation</h2>
			<p>Le projet voice-recognition.js est une biblioth&egrave;que pour la reconnaissance vocale de mots isol&eacute;s. Elle est capable de distinguer deux expressions, comme &laquo; avance &raquo; et &laquo; recule &raquo; par exemple.</p>
			<p>Javascript est utilis&eacute; principalement, mais aussi Flash pour faire l'interface entre Javascript et le microphone, en attendant que les navigateurs r&eacute;cents supportent la capture du microphone.</p>

			<h2 id="docs-general-functioning">2. Fonctionnement g&eacute;n&eacute;ral</h2>
			<p>Le principe sur lequel repose l'algorithme de reconnaissance vocale est simple : la construction de <abbr title="Discrete Fourier Transform">DFT</abbr> (transform&eacute;e de Fourier discr&egrave;te, par l'aglorithme <abbr title="Fast Fourier Transform">FFT</abbr>) &agrave; partir des enregistrements vocaux et la comparaison de ces donn&eacute;es pour d&eacute;terminer lesquelles sont les plus similaires.</p>
			<p>Le signal audio prononc&eacute; va &ecirc;tre compar&eacute; &agrave; des mod&egrave;les pr&eacute;-enregistr&eacute;s contenus dans une base de donn&eacute;es.</p>
			<ul class="thumbnails">
				<li class="span12">
					<div class="thumbnail">
						<img src="img/docs/general-functioning.png" alt="Fonctionnement g&eacute;n&eacute;ral"/>
					</div><!-- /.thumbnail -->
				</li><!-- /.span12 -->
			</ul><!-- /.thumbnails -->
			<a href="json/models.json" class="btn btn-mini btn-info pull-right" target="_blank">Voir un exemple</a>
			<p>Les mod&egrave;les sont stock&eacute;s sous le format JSON et respectent cette syntaxe :</p>
			<pre><code>[ //Tableau contenant les diff&eacute;rents mod&egrave;les
	{ //Premier groupe de mod&egrave;les
		"name": "avance", //Nom du groupe
		"models": [ //Mod&egrave;les appartenant au groupe
			{ //Premier mod&egrave;le
				"name": "avance", //Nom du mod&egrave;le
				"gender": "m", //Sexe du locuteur ("m" pour masculin, "f" pour f&eacute;minin)
				"speaker": "simon", //Nom du locuteur
				"micro": "simon-samsung-shs-200v", //Nom du micro utilis&eacute;
				"data": { //Donn&eacute;es du mod&egrave;le
					"magnitude": [...], //Magnitudes
					"time": [...], //Temps
					"frequencies": [...] //Fr&eacute;quences enregistr&eacute;es
				}
			}
		]
	},
	{ //Deuxi&egrave;me groupe de mod&egrave;les
		"name": "recule",
		"models": [
			{
				"name": "recule",
				"gender": "m",
				"speaker": "simon",
				"micro": "simon-samsung-shs-200v",
				"data": {
					"magnitude": [...],
					"time": [...],
					"frequencies": [...]
				}
			}
		]
	}
]</code></pre>
			<p>Il est possible de g&eacute;n&eacute;rer des fichiers de mod&egrave;les sur la page &laquo; <a href="voice-analysis.html">Voice analysis &amp; comparison</a> &raquo; en enregistrant deux mots, en renommant les analyses correspondantes et en utilisant le bouton &laquo; Build a voice model &raquo;.</p>

			<h2 id="docs-signal-processing">3. Traitement du signal</h2>
			<p>Les API HTML5 de Mozilla (en particulier <a href="https://developer.mozilla.org/en-US/docs/Introducing_the_Audio_API_Extension">Audio Data API</a>) nous permettent de r&eacute;cup&eacute;rer les donn&eacute;es brutes du signal audio provenant d'un fichier.</p>
			<p>Dans le cas d'un enregistrement vocal provenant du microphone, la sp&eacute;cification est encore obscure et il n'existe aucune impl&eacute;mentation pour le moment. Nous devons donc recourir &agrave; une petite biblioth&egrave;que Flash pour acc&eacute;der aux donn&eacute;es brutes. Ce programme s'appelle <a href="https://github.com/jwagener/recorder.js">recorder.js</a>, il a &eacute;t&eacute; modifi&eacute; pour permettre l'acc&egrave;s aux donn&eacute;es en temps r&eacute;el et non apr&egrave;s l'enregistrement pour plus de rapidit&eacute; et une visualisation du signal en direct (cf. <a href="https://github.com/simonser/recorder.js">le <em>fork</em> sur Github</a>).</p>
			<button class="btn btn-mini btn-info pull-right" type="button" onclick="Docs.browseCode('js/lib/voice-analysis.js', 1, 112);">Voir le code</button>
			<p>Une fois les donn&eacute;es du signal r&eacute;cup&eacute;r&eacute;es, il nous faut dessiner une <abbr title="Discrete Fourier Transform">DFT</abbr>. On utilisera alors la classe <em>FFT</em> issue de <a href="https://github.com/corbanbrook/dsp.js"><abbr title="Digital Signal Processing">dsp</abbr>.js</a>. Une <a href="https://fr.wikipedia.org/wiki/Transform%C3%A9e_de_Fourier_discr%C3%A8te">DFT</a> est une d&eacute;composition fr&eacute;quencielle du signal sonore et permet de l'exploiter.</p>
			<ul class="thumbnails">
				<li class="span12">
					<div class="thumbnail">
						<img src="https://upload.wikimedia.org/wikipedia/commons/5/58/TFD.JPG" alt="Exemple TransformÃ©e de Fourier Discrete"/>
					</div><!-- /.thumbnail -->
				</li><!-- /.span12 -->
			</ul><!-- /.thumbnails -->
			<p>&Agrave; intervale de temps r&eacute;gulier, on cr&eacute;e une FFT du signal. Apr&egrave;s le traitement, on a donc une collection de FFT.</p>
			<ul class="thumbnails">
				<li class="span12">
					<div class="thumbnail">
						<img src="img/docs/fft-collection-create.png" alt="Cr&eacute;ation de la collection de FFT"/>
					</div><!-- /.thumbnail -->
				</li><!-- /.span12 -->
			</ul><!-- /.thumbnails -->

			<h2 id="docs-fft-processing">4. Traitement de la FFT</h2>
			<button class="btn btn-mini btn-info pull-right" type="button" onclick="Docs.browseCode('js/lib/voice-analysis.js', 468, 484);">Voir le code</button>
			<p>Une fois la collection de FFT obtenue, on va normaliser ces FFT sur l'axe des magnitudes. Cela va permettre de pouvoir comparer les FFT entre elles m&ecirc;me si le niveau sonore est diff&eacute;rent, par exemple si l'utilisateur a parl&eacute; plus proche du micro ou plus fort.</p>
			<ul class="thumbnails">
				<li class="span12">
					<div class="thumbnail">
						<img src="img/docs/fft-normalize-magnitude.png" alt="Normalisation sur l'axe des magnitudes"/>
					</div><!-- /.thumbnail -->
				</li><!-- /.span12 -->
			</ul><!-- /.thumbnails -->
			<button class="btn btn-mini btn-info pull-right" type="button" onclick="Docs.browseCode('js/lib/voice-analysis.js', 486, 539);">Voir le code</button>
			<p>Il nous faut maintenant d&eacute;terminer le d&eacute;but et la fin du mot prononc&eacute;. Pour cela, nous allons d&eacute;finir un seuil &agrave; partir duquel on consid&eacute;rera que le mot commence ou finit d'&ecirc;tre prononc&eacute;.</p>
			<ul class="thumbnails">
				<li class="span12">
					<div class="thumbnail">
						<img src="img/docs/fft-threshold.png" alt="D&eacute;termination du d&eacute;but et de la fin"/>
					</div><!-- /.thumbnail -->
				</li><!-- /.span12 -->
			</ul><!-- /.thumbnails -->
			<button class="btn btn-mini btn-info pull-right" type="button" onclick="Docs.browseCode('js/lib/voice-analysis.js', 541, 561);">Voir le code</button>
			<p>Ensuite, une normalisation de l'axe du temps est effectu&eacute;e. 0% va donc correspondre au d&eacute;but du mot et 100% &agrave; sa fin.</p>
			<ul class="thumbnails">
				<li class="span12">
					<div class="thumbnail">
						<img src="img/docs/fft-normalize-time.png" alt="Normalisation sur l'axe du temps"/>
					</div><!-- /.thumbnail -->
				</li><!-- /.span12 -->
			</ul><!-- /.thumbnails -->

			<h2 id="docs-audio-comparison">5. Comparaison entre deux pistes audio</h2>
			<p>Une fois ces traitements effectu&eacute;s, il est alors possible de comparer les donn&eacute;es obtenues.</p>

			<h3 id="docs-data-preparing">a) Pr&eacute;paration des donn&eacute;es</h3>
			<p>Nos donn&eacute;es sont sous la forme de deux collections de FFT, chacune faisant correspondre un temps donn&eacute; et une FFT. Le probl&egrave;me est que les FFT n'ont pas for&eacute;ment &eacute;t&eacute; construites &agrave; un temps identique : par exemple, un enregistrement de 1,4 s. et un autre de 1,6 s. n'ont pas le m&ecirc;me nombre de FFT construites. Le but sera donc de transformer les donn&eacute;es de fa&ccedil;on &agrave; faire correspondre un temps donn&eacute; avec deux FFT.</p>
			<ul class="thumbnails">
				<li class="span12">
					<div class="thumbnail">
						<img src="img/docs/comparison-prepare.png" alt="Pr&eacute;paration des donn&eacute;es"/>
					</div><!-- /.thumbnail -->
				</li><!-- /.span12 -->
			</ul><!-- /.thumbnails -->
			<button class="btn btn-mini btn-info pull-right" type="button" onclick="Docs.browseCode('js/lib/voice-comparison.js', 77, 196);">Voir le code</button>
			<p>L'algorithme va prendre la collection de FFT la plus importante et y ajouter les donn&eacute;es de l'autre.</p>

			<h3 id="docs-data-shifting">b) D&eacute;calage des courbes <span class="label label-warning">Fonctionne mal</span></h3>
			<div class="alert alert-block">
				<h4>Attention !</h4>
				Cette fonctionnalit&eacute; ne marche pas comme attendu. Elle est optionnelle et ses r&eacute;sultats n'ont pas encore &eacute;t&eacute; &eacute;tudi&eacute;s. Ne l'utilisez donc pas !
			</div>
			<button class="btn btn-mini btn-info pull-right" type="button" onclick="Docs.browseCode('js/lib/voice-comparison.js', 213, 322);">Voir le code</button>
			<p>Un algorithme va se charger de d&eacute;caler les courbes des FFT pour qu'elles correspondent au mieux.</p>

			<h3 id="docs-comparing">c) Comparaison des courbes</h3>
			<button class="btn btn-mini btn-info pull-right" type="button" onclick="Docs.browseCode('js/lib/voice-comparison.js', 329, 389);">Voir le code</button>
			<p>Ensuite, nous allons comparer les deux courbes de chaque couple de FFT. Un indicateur de correspondance sera d&eacute;termin&eacute; pour chaque point de la courbe (donc pour chaque fr&eacute;quence), une moyenne en sera faite au niveau de la FFT puis de la collection de FFT.</p>
			<ul class="thumbnails">
				<li class="span12">
					<div class="thumbnail">
						<img src="img/docs/comparison-compare.png" alt="Comparaison de deux FFT"/>
					</div><!-- /.thumbnail -->
				</li><!-- /.span12 -->
			</ul><!-- /.thumbnails -->
			<p>Notons que les premi&egrave;res fr&eacute;quences &eacute;tant tr&egrave;s d&eacute;pendantes du bruit de fond donc assez al&eacute;atoires, nous les excluons de la comparaison.</p>

			<h2 id="docs-voice-recognition">6. Reconnaissance vocale</h2>
			<p>Il est alors simple de d&eacute;terminer quel mod&egrave;le correspond au mieux au mot prononc&eacute; : celui dont la correspondance avec le signal audio est la plus importante.</p>
			<ul class="thumbnails">
				<li class="span12">
					<div class="thumbnail">
						<img src="img/docs/voice-recognition.png" alt="Reconnaissance vocale"/>
					</div><!-- /.thumbnail -->
				</li><!-- /.span12 -->
			</ul><!-- /.thumbnails -->
			<p>Le r&eacute;sultat est alors affich&eacute; &agrave; l'&eacute;cran, avec diff&eacute;rents indicateurs : taux de d&eacute;viation (plus il est grand, moins les courbes correspondent - deux courbes identiques ont une d&eacute;viation &eacute;gale &agrave; 0), l'&eacute;cart-type et le taux d'erreur (diff&eacute;rence entre les taux de d&eacute;viation des deux meilleurs mod&egrave;les).</p>
			<button class="btn btn-mini btn-info pull-right" type="button" onclick="Docs.browseCode('js/plugin/');">Voir le code</button>
			<p>L'ajout de modules compl&eacute;mentaires (cf. le dossier <a href="js/plugin" target="_blank"><em>js/plugin</em></a>) permet entre autres d'effectuer des actions &agrave; l'issue d'une reconnaissance vocale. Par exemple, il est possible d'envoyer une requ&ecirc;te vers un serveur <a href="http://symbiose.fr.cr" target="_blank">Symbiose</a> pour activer ou d&eacute;sactiver des pins GPIO d'un <a href="http://www.raspberrypi.org/" target="_blank">Raspberry Pi</a>. Un robot &agrave; reconnaissance vocale a d&eacute;j&agrave; &eacute;t&eacute; r&eacute;alis&eacute; &agrave; l'aide de voice-recognition.js.</p>
		</div>
	</div>
</div>

<script src="http://code.jquery.com/jquery-latest.js"></script>
<script src="js/lib/bootstrap.min.js"></script>
<script src="js/pages/index.js"></script>
</body>
</html>